# 爬虫本质

模拟浏览器打开网页，获取网页中我们想要的那部分数据
其实搜索引擎就是先爬取各个网页内容，然后放在自己的数据库里面，创建索引，  
在索引中进行分类、归档、排序，然后将结果返回给用户

+ 准备工作
  通过浏览器查看分析目标网页
+ 获取数据
  通过HTTP库向目标占点发起请求，请求可以包含额外的header等信息，如果服务器能正常响应，会得到一个Response这便是所要获取的页面内容
+ 解析内容
  得到的内容可能是HTML和json等格式，可以用页面解析式、正则表达式等进行解析
+ 保存数据
  保存形式多种多样，可以存为文本，也可以保存到数据库，或者保存特定格式的文件  

  浏览器和服务器